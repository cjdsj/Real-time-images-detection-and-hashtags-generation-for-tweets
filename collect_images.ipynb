{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87bd8987",
   "metadata": {},
   "source": [
    "# 0. Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632bb3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json \n",
    "import pandas as pd\n",
    "import urllib\n",
    "import os\n",
    "import time\n",
    "from os import path\n",
    "import progressbar\n",
    "from imagededup.methods import PHash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074924f8",
   "metadata": {},
   "source": [
    "### Use following code to install package imagededup if the package is not applicable  \n",
    "`pip install imagededup`  or  `pip install imagededup --user`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604870b",
   "metadata": {},
   "source": [
    "## Dataset and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ad323",
   "metadata": {},
   "source": [
    "Find the corresponding labels and model from the below website:  \n",
    "https://www.kaggle.com/datasets/piyushkumar18/animal-image-classification-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f319570",
   "metadata": {},
   "source": [
    "# 1. Train Set Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7107dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "        Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "    \n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"6998final\"\n",
    "    \n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url):\n",
    "    '''\n",
    "        connect with given url\n",
    "        \n",
    "        #param:\n",
    "            url: (str) query with user-defined conditions\n",
    "        \n",
    "        #return:\n",
    "            json format response with provided fields\n",
    "    '''\n",
    "    \n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
    "#     print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def save_to_file(tweet, save_path):\n",
    "    '''\n",
    "        save the attached img(s) by matching tag\n",
    "        \n",
    "        #param:\n",
    "            tweet: (json) metadata of the streaming tweet\n",
    "            save_path: (str) local path to save img\n",
    "        \n",
    "        #return:\n",
    "            None\n",
    "    '''\n",
    "    \n",
    "    createDir(save_path)\n",
    "    try:\n",
    "        tweet['includes']['media']\n",
    "    except:\n",
    "#         print('key error, no attachmentss included')\n",
    "        return\n",
    "    \n",
    "    for img in tweet['includes']['media']:\n",
    "        try:\n",
    "            media_url = img['url']\n",
    "            media_key = img['media_key']\n",
    "            pic = urllib.request.urlopen(media_url)\n",
    "            exist_file = os.listdir(save_path)\n",
    "            if (media_key + '.jpg') not in exist_file:\n",
    "                file_path = save_path+ \"/\" + media_key + \".jpg\"\n",
    "                with open(file_path, 'wb') as localFile:\n",
    "                    localFile.write(pic.read())\n",
    "#             tweet_list.append([data['id'], media_url, data['text']])\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "def createDir(save_path):\n",
    "    '''\n",
    "        create dir path with given save_path, print error when path already exists.\n",
    "        \n",
    "        #param:\n",
    "            save_path: (str) local path to save img\n",
    "        \n",
    "        #return:\n",
    "            None\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(save_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "        \n",
    "def bar(tag):\n",
    "    \"\"\"\n",
    "        create progress bar with tag info\n",
    "        \n",
    "        #param:\n",
    "            tag: (str) display info at the bar\n",
    "            \n",
    "        #return:\n",
    "            None\n",
    "    \"\"\"\n",
    "    \n",
    "    return progressbar.ProgressBar(\n",
    "    widgets=[\n",
    "        'Loading ' + tag + ' images', \n",
    "        ' ', progressbar.Percentage(),\n",
    "        ' ', progressbar.Bar('#'),\n",
    "        ' ', progressbar.Timer(),\n",
    "        ' ( ', progressbar.ETA(), ' ) ', \n",
    "    ]\n",
    "    )\n",
    "\n",
    "def deduplicate(img_path):\n",
    "    \"\"\"\n",
    "        deduplicate img in the given path\n",
    "        \n",
    "        #param:\n",
    "            img_path: local path of the \n",
    "        \n",
    "        #reutrn:\n",
    "            None\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        phasher = PHash()\n",
    "        # generate hash value for all img in current dir\n",
    "        encodings = phasher.encode_images(image_dir=img_path)\n",
    "\n",
    "        # find duplicate img\n",
    "        duplicates = phasher.find_duplicates(encoding_map=encodings)\n",
    "        # print(duplicates)\n",
    "        only_img = []  # unique img\n",
    "        like_img = []  # similar img\n",
    "\n",
    "        for img, img_list in duplicates.items():\n",
    "            if \".png\" in img:\n",
    "                continue\n",
    "            if img not in only_img and img not in like_img:\n",
    "                only_img.append(img)\n",
    "                like_img.extend(img_list)\n",
    "\n",
    "        # delete file\n",
    "        for like in like_img:\n",
    "            like_src = os.path.join(img_path, like)\n",
    "            png_src = like_src[:-4] + \".png\"\n",
    "            if os.path.exists(like_src):\n",
    "                os.remove(like_src)\n",
    "            if os.path.exists(png_src):\n",
    "                os.remove(png_src)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b32ad8",
   "metadata": {},
   "source": [
    "## Train Set Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "097bb499",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading horse images 100% |##########| Elapsed Time: 0:23:54 ( Time: 0:23:54 ) \n",
      "Loading monkey images 100% |#########| Elapsed Time: 0:08:43 ( Time: 0:08:43 ) \n",
      "Loading panda images 100% |##########| Elapsed Time: 0:27:41 ( Time: 0:27:41 ) \n"
     ]
    }
   ],
   "source": [
    "# replace the token by your own\n",
    "bearer_token = \"\"\n",
    "max_results = 10000\n",
    "\n",
    "def test():\n",
    "    # endpoint of twitter recent search\n",
    "    endpoint = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "    \n",
    "    # default settings\n",
    "    media_fields = '&media.fields=duration_ms,height,media_key,preview_image_url,public_metrics,type,url,width' \n",
    "    expansion = '&expansions=attachments.media_keys'\n",
    "    \n",
    "    # total number of results to return, should be in [10, 100]\n",
    "    number = '&max_results=100'\n",
    "    # local path to save img\n",
    "    save_path = './dataset'\n",
    "    # number of iterations per tag, suggested more than 400\n",
    "    iteration = 500\n",
    "    \n",
    "    # replace with your demand tags\n",
    "#     tags = ['butterfly','cats','cow','dogs','elephant','hen','horse','monkey','panda','sheep','spider','squirrel']\n",
    "    tags = ['horse','monkey','panda']\n",
    "    \n",
    "    for tag in tags:\n",
    "        # get progressbar\n",
    "        mybar = bar(tag)\n",
    "        path = save_path + '/' + tag\n",
    "        sign_change = False\n",
    "        query = '?query=%23{}%20has%3Aimages'.format(tag)\n",
    "        sign_dep = False\n",
    "        \n",
    "        for t in mybar(range(iteration)):\n",
    "            if t == 0:\n",
    "                token = ''\n",
    "            else:\n",
    "                try:\n",
    "                    json_response['meta']['next_token']\n",
    "                    token = '&next_token={}'.format(json_response['meta']['next_token'])\n",
    "                except:\n",
    "                    if sign_change:\n",
    "                        print('all records loaded for tag {}!'.format(tag))\n",
    "                        break\n",
    "\n",
    "                    sign_change = True\n",
    "                    query = '?query={}%20has%3Aimages'.format(tag)  \n",
    "                    token = ''\n",
    "\n",
    "            # query = '?query=%23{}%20OR%20{}%20has%3Aimages'.format(tag, tag)  \n",
    "            search_url = endpoint + query + expansion + media_fields + number + token\n",
    "            json_response = connect_to_endpoint(search_url)\n",
    "            save_to_file(json_response, path)\n",
    "\n",
    "            # deduplicate when records are more than max_results\n",
    "            if len(os.listdir(path)) >= max_results:\n",
    "                deduplicate(path)\n",
    "                sign_dep = True\n",
    "                \n",
    "            if len(os.listdir(path)) >= max_results:\n",
    "                break\n",
    "        if not sign_dep:\n",
    "            deduplicate(path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load img from twitter\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb2410",
   "metadata": {},
   "source": [
    "### check img numbers within each tag path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11344095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total img under horse\n",
      "5805\n",
      "total img under monkey\n",
      "1880\n",
      "total img under panda\n",
      "5382\n"
     ]
    }
   ],
   "source": [
    "path = './dataset'\n",
    "for subfile in os.listdir(path):\n",
    "    print('total img under '+subfile)\n",
    "    print(len(os.listdir(path + '/' + subfile)))\n",
    "\n",
    "# pending = ['butterfly','cats','dogs','horse','panda']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcbcd0d",
   "metadata": {},
   "source": [
    "# 2. Streaming Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_headers(bearer_token):\n",
    "    '''\n",
    "        create request header for given bearer_token account\n",
    "        \n",
    "        #param:\n",
    "            bearer_token: (str) get your own at https://developer.twitter.com/en/portal/dashboard \n",
    "        \n",
    "        #return:\n",
    "            json format headers with authorized bearer_token\n",
    "    '''  \n",
    "    \n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    \n",
    "    return headers\n",
    "        \n",
    "def set_rules(headers, bearer_token, rules):\n",
    "    '''\n",
    "        set stream rules for given bearer_token account\n",
    "        \n",
    "        #param:\n",
    "            headers: request header for twitter api \n",
    "            bearer_token: (str) get your own at https://developer.twitter.com/en/portal/dashboard \n",
    "            rules: (json) with rule value and corresponding tag (optional)\n",
    "            \n",
    "        #return: \n",
    "            None\n",
    "    '''  \n",
    "    \n",
    "    payload = {\"add\": rules}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        headers=headers,\n",
    "        json=payload,\n",
    "    )\n",
    "    if response.status_code != 201:\n",
    "        raise Exception(\n",
    "            \"Cannot add rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print('following rules have been set: ')\n",
    "    print(json.dumps(response.json()))\n",
    "    \n",
    "def get_rules(headers, bearer_token):\n",
    "    '''\n",
    "        get current stream rules for given bearer_token account\n",
    "        \n",
    "        #param:\n",
    "            headers: request header for twitter api \n",
    "            bearer_token: (str) get your own at https://developer.twitter.com/en/portal/dashboard \n",
    "            \n",
    "        #return:\n",
    "            json format rules that have been created on the given account\n",
    "    '''  \n",
    "    \n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\", headers=headers\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print('current stream rules: ')\n",
    "    print(json.dumps(response.json()))\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def delete_all_rules(headers, bearer_token, rules):\n",
    "    '''\n",
    "        delete current stream rules for given bearer_token account\n",
    "        \n",
    "        #param:\n",
    "            headers: request header for twitter api \n",
    "            bearer_token: (str) get your own at https://developer.twitter.com/en/portal/dashboard \n",
    "            rules: (json) with rule value and corresponding tag (optional)\n",
    "            \n",
    "        #return:\n",
    "            None\n",
    "    '''    \n",
    "    \n",
    "    if rules is None or \"data\" not in rules:\n",
    "        return None\n",
    "\n",
    "    ids = list(map(lambda rule: rule[\"id\"], rules[\"data\"]))\n",
    "    payload = {\"delete\": {\"ids\": ids}}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot delete rules (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "\n",
    "def get_stream(headers, bearer_token, expansions, fields, save_to_disk, save_path, total):\n",
    "    '''\n",
    "        streaming data from twitter with bearer_token\n",
    "        \n",
    "        #param:\n",
    "            headers: request header for twitter api \n",
    "            bearer_token: (str) get your own at https://developer.twitter.com/en/portal/dashboard \n",
    "            expansions: (str) attachment requirement\n",
    "            fields: (str) media fields requirement\n",
    "            save_to_disk: (bool) true for save to disk and false for not\n",
    "            save_path: (str) local path to save img\n",
    "            total: (int) total number of results to save \n",
    "        \n",
    "        #return:\n",
    "            None\n",
    "    '''\n",
    "        \n",
    "    data = []\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream\" + expansions + fields, headers=headers, stream=True,\n",
    "    )\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get stream (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    num = 0\n",
    "    for response_line in response.iter_lines():\n",
    "        if num >= total:\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                json_response = json.loads(response_line)\n",
    "                if save_to_disk == True:\n",
    "                    save_media_to_disk_stream(json_response, save_path)\n",
    "                num += 1\n",
    "            except (json.JSONDecodeError, KeyError) as err:\n",
    "\n",
    "                continue \n",
    "        \n",
    "def save_media_to_disk_stream(tweet, save_path):\n",
    "    '''\n",
    "        save the attached img(s) by matching tag\n",
    "        \n",
    "        #param:\n",
    "            tweet: (json) metadata of the streaming tweet\n",
    "            save_path: (str) local path to save img\n",
    "        \n",
    "        #return:\n",
    "            None\n",
    "    '''\n",
    "    \n",
    "    data = tweet['data']\n",
    "    includes = tweet['includes']\n",
    "    media = includes['media']\n",
    "    \n",
    "    save_path += '/' + tweet[\"matching_rules\"][0][\"tag\"]\n",
    "    createDir(save_path)\n",
    "    \n",
    "    for line in media:\n",
    "        media_url = line['url']\n",
    "        media_key = line['media_key']\n",
    "        pic = urllib.request.urlopen(media_url)\n",
    "\n",
    "        try:\n",
    "            exist_file = os.listdir(save_path)\n",
    "            if (media_key + '.jpg') in exist_file:\n",
    "                continue\n",
    "                \n",
    "            file_path = save_path+ \"/\" + media_key + \".jpg\"\n",
    "            with open(file_path, 'wb') as localFile:\n",
    "                localFile.write(pic.read())\n",
    "#             tweet_list.append([data['id'], media_url, data['text']])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "def createDir(save_path):\n",
    "    '''\n",
    "        create dir path with given save_path, print error when path already exists.\n",
    "        \n",
    "        #param:\n",
    "            save_path: (str) local path to save img\n",
    "        \n",
    "        #return:\n",
    "            None\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(save_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029e42e",
   "metadata": {},
   "source": [
    "# Main Call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879cdd3d",
   "metadata": {},
   "source": [
    "## 1. Query image with multiple match rules, total results as max_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # replace the token by your own\n",
    "    bearer_token = \"AAAAAAAAAAAAAAAAAAAAAH30awEAAAAA%2Fn7raIY9wrtGrl8YN9vWMwR9kic%3DFUPmD2bXugVrsh0Sw2Ta1aO2nDTKcPzpjutNQ2cGqIPS1s6x70\"\n",
    "\n",
    "    # total max results to save\n",
    "    max_results = 1000\n",
    "\n",
    "    # default settings\n",
    "    media_fields = \"&media.fields=duration_ms,height,media_key,preview_image_url,public_metrics,type,url,width\"\n",
    "    expansions = \"?expansions=attachments.media_keys\"\n",
    "\n",
    "    # replace with your own labels with prefix #\n",
    "    # notice here within a group there should be no more than five tags\n",
    "    tags = [['#butterfly', '#cat', '#cow', '#dog'],  ['#horse', '#elephant', '#hen', '#monkey'], ['#panda', \n",
    "            '#sheep', '#spider', '#squirrel']]\n",
    "\n",
    "    # replace with your own dir location to save img\n",
    "    save_path = './dataset'\n",
    "    for group in tags:\n",
    "        search_rules = []\n",
    "        for tag in group:\n",
    "        # adjust the rules if needed\n",
    "            search_rules.append({'value': tag + ' has:images', \n",
    "                                 'tag': tag.replace('#', '')\n",
    "                                })\n",
    "        headers = create_headers(bearer_token)\n",
    "        rules = get_rules(headers, bearer_token)\n",
    "        delete = delete_all_rules(headers, bearer_token, rules)\n",
    "        set1 = set_rules(headers, delete, bearer_token, search_rules)\n",
    "        get_stream(headers, bearer_token, expansions, media_fields, save_to_disk=True, save_path=save_path, total=max_results)\n",
    "\n",
    "# df = pd.DataFrame (tweet_list, columns = ['tweet_id', 'preview_image_url', 'tweet_text'])\n",
    "# df.to_csv('streaming_' + tag + '.csv')\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5faec06",
   "metadata": {},
   "source": [
    "## 2. Query with single tag, result per tag as max_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    tags = ['#butterfly', '#cat', '#cow', '#dog',  '#horse']\n",
    "    media_fields = \"&media.fields=duration_ms,height,media_key,preview_image_url,public_metrics,type,url,width\"\n",
    "    expansions = \"?expansions=attachments.media_keys\"\n",
    "    search_rules = []\n",
    "    max_results = 1000\n",
    "\n",
    "    for tag in tags:\n",
    "        # adjust the rules if needed\n",
    "        search_rules = [\n",
    "            {'value': tag + ' has:images', \n",
    "             'tag': tag.replace('#', '')\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        save_path = './dataset'\n",
    "\n",
    "        headers = create_headers(bearer_token)\n",
    "        rules = get_rules(headers, bearer_token)\n",
    "        delete = delete_all_rules(headers, bearer_token, rules)\n",
    "        set1 = set_rules(headers, delete, bearer_token, search_rules)\n",
    "        get_stream(headers, bearer_token, expansions, media_fields, save_to_disk=True, save_path=save_path, total=max_results)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
